# =============================================================================
# CIRISBench AgentBeats Configuration
# =============================================================================
# Copy to .env and customize as needed
#
# Quick Start:
#   cp .env.example .env
#   docker compose up -d
#
# =============================================================================

# -----------------------------------------------------------------------------
# Image Settings
# -----------------------------------------------------------------------------
DOCKER_REGISTRY=ghcr.io/cirisai
IMAGE_TAG=agentbeats
VERSION=0.1.0

# -----------------------------------------------------------------------------
# Service Ports
# -----------------------------------------------------------------------------
CIRISNODE_PORT=8000    # CIRISNode API (MCP/A2A endpoints)
EEE_PORT=8080          # EthicsEngine API (benchmarks)
OLLAMA_PORT=11434      # Ollama LLM (if using GPU profile)

# -----------------------------------------------------------------------------
# Protocol Settings
# -----------------------------------------------------------------------------
MCP_ENABLED=true       # Enable Model Context Protocol
A2A_ENABLED=true       # Enable Agent-to-Agent protocol

# -----------------------------------------------------------------------------
# LLM Configuration (for semantic evaluation)
# -----------------------------------------------------------------------------
# Choose ONE provider by setting LLM_PROVIDER:
#   - ollama (local, requires GPU)
#   - openai (requires OPENAI_API_KEY)
#   - anthropic (requires ANTHROPIC_API_KEY)
#   - openrouter (recommended, requires OPENROUTER_API_KEY)

LLM_PROVIDER=openrouter
LLM_MODEL=openai/gpt-4o-mini

# OpenRouter (recommended - access to multiple models)
# OPENROUTER_API_KEY=sk-or-...

# OpenAI (direct)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# OPENAI_API_KEY=sk-...

# Anthropic (direct)
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-haiku-20240307
# ANTHROPIC_API_KEY=sk-ant-...

# Local Ollama (use --profile gpu)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2
# OLLAMA_BASE_URL=http://ollama:11434

# -----------------------------------------------------------------------------
# Benchmark Settings
# -----------------------------------------------------------------------------
HE300_SAMPLE_SIZE=300  # Scenarios per benchmark run (1-300)
HE300_SEED=42          # Random seed for reproducibility
HE300_CONCURRENCY=50   # Parallel calls (10, 50, or 100)

# -----------------------------------------------------------------------------
# AgentBeats Platform (provided by AgentBeats when running)
# -----------------------------------------------------------------------------
# AGENTBEATS_API_KEY=           # API key for incoming requests
# AGENTBEATS_WEBHOOK_SECRET=    # Secret for signing callbacks
# AGENTBEATS_RUN_ID=            # Unique run identifier

# Callback URL for sending results back to AgentBeats
# Format: https://agentbeats.dev/api/hook/v2/{your-hook-id}
# AGENTBEATS_CALLBACK_URL=https://agentbeats.dev/api/hook/v2/019c05dd-2a25-71f1-ad2b-76e205a6de0e

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
LOG_LEVEL=info         # debug, info, warning, error

# -----------------------------------------------------------------------------
# Full Stack (--profile full)
# -----------------------------------------------------------------------------
# Database
POSTGRES_USER=ciris
POSTGRES_PASSWORD=ciris
POSTGRES_DB=cirisbench
DATABASE_URL=postgresql://ciris:ciris@postgres:5432/cirisbench

# Redis
REDIS_URL=redis://redis:6379/0
